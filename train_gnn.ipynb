{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f300d7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch version: 2.8.0+cu128\n",
      "CUDA available: True\n",
      "CUDA version: 12.8\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"CUDA version: {torch.version.cuda}\")   # type: ignore\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "PYG_GRAPHS = torch.load(\"data/processed/pyg_graphs_384D.pt\", weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79d237b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## HELPER FUNCTIONS FOR CREATING AND TRAINING MODEL\n",
    "import importlib\n",
    "import src.models.multitask_debate_gnn\n",
    "importlib.reload(src.models.multitask_debate_gnn)\n",
    "\n",
    "from src.models.multitask_debate_gnn import ECCConv, MultitaskDebateGNN, train_gnn_live, plot_cv_losses\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from typing import Dict, Any, Type, Optional\n",
    "\n",
    "def create_and_describe_model(model_args: Dict[str, Any], model_class: Type[MultitaskDebateGNN] = MultitaskDebateGNN) -> Optional[MultitaskDebateGNN]:\n",
    "    \"\"\"Build the model from args, print a summary, and return the instance (or None on failure).\"\"\"\n",
    "    try:\n",
    "        model = model_class(**model_args)\n",
    "        print(\"Model created:\")\n",
    "        print(f\"   Architecture: {[type(conv).__name__ for conv in model.convs]}\")\n",
    "        print(f\"   Mode: {model.mode}\")\n",
    "        print(f\"   Input dim: {model_args['in_dim']}\")\n",
    "        print(f\"   Hidden dim: {model_args['hidden_dim']}\")\n",
    "        print(f\"   Embedding dim: {model_args['emb_dim']}\")\n",
    "        print(f\"   Number of layers: {model_args['num_layers']}\")\n",
    "\n",
    "        # Count parameters\n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "        print(\"\\nModel Statistics:\")\n",
    "        print(f\"   Total parameters: {total_params:,}\")\n",
    "        print(f\"   Trainable parameters: {trainable_params:,}\")\n",
    "        print(f\"   Model size: ~{total_params * 4 / 1024**2:.1f} MB\")\n",
    "\n",
    "        # Show model structure\n",
    "        print(\"\\nModel Structure:\")\n",
    "        print(model)\n",
    "        return model\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error creating model: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return None\n",
    "    \n",
    "def run_cv_training(\n",
    "    graph_data,\n",
    "    model_args: dict,\n",
    "    train_args: dict,\n",
    "    model_class: Type[MultitaskDebateGNN] = MultitaskDebateGNN,\n",
    "    live_plot: bool = False,):\n",
    "    \"\"\"\n",
    "    Runs cross-validation training with cleanup and plotting.\n",
    "    Returns (model, results, cv_history) or (None, None, None) on failure.\n",
    "    \"\"\"\n",
    "    import gc, traceback\n",
    "    import torch\n",
    "\n",
    "    gc.collect()\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    try:\n",
    "        model, results, cv_history = train_gnn_live(\n",
    "            all_graphs=getattr(graph_data, \"pyg_graphs\", graph_data),\n",
    "            model_args=model_args,\n",
    "            train_args=train_args,\n",
    "            model_class=model_class,\n",
    "            live_plot=live_plot,\n",
    "        )\n",
    "        plot_cv_losses(cv_history=cv_history)\n",
    "        return model, results, cv_history\n",
    "    except Exception as e:\n",
    "        print(f\"Training error: {e}\")\n",
    "        traceback.print_exc()\n",
    "        return None, None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a9a3685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model created:\n",
      "   Architecture: ['SAGEConv', 'SAGEConv', 'ECCConv']\n",
      "   Mode: full\n",
      "   Input dim: 384\n",
      "   Hidden dim: 256\n",
      "   Embedding dim: 128\n",
      "   Number of layers: 3\n",
      "\n",
      "Model Statistics:\n",
      "   Total parameters: 4,741,704\n",
      "   Trainable parameters: 4,741,704\n",
      "   Model size: ~18.1 MB\n",
      "\n",
      "Model Structure:\n",
      "MultitaskDebateGNN(\n",
      "  (convs): ModuleList(\n",
      "    (0): SAGEConv(384, 256, aggr=mean)\n",
      "    (1): SAGEConv(256, 256, aggr=mean)\n",
      "    (2): ECCConv(256, 128)\n",
      "  )\n",
      "  (norms): ModuleList(\n",
      "    (0-1): 2 x LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (activation): GELU(approximate='none')\n",
      "  (dropout): Dropout(p=0.15, inplace=False)\n",
      "  (skip): Linear(in_features=384, out_features=128, bias=True)\n",
      "  (link_head): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.15, inplace=False)\n",
      "    (3): Linear(in_features=128, out_features=1, bias=True)\n",
      "  )\n",
      "  (edge_head): Sequential(\n",
      "    (0): Linear(in_features=256, out_features=256, bias=True)\n",
      "    (1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
      "    (2): GELU(approximate='none')\n",
      "    (3): Dropout(p=0.15, inplace=False)\n",
      "    (4): Linear(in_features=256, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "MODEL_ARGS = dict(\n",
    "    in_dim = 384,\n",
    "    hidden_dim = 256,\n",
    "    emb_dim = 128,\n",
    "    neg_attr_weight = 0.3,\n",
    "    dropout = 0.15,\n",
    "    num_layers=3,\n",
    "    mode=\"full\",\n",
    "    conv_cls_list=[SAGEConv, SAGEConv, ECCConv],\n",
    "    ecc_kwargs=dict(\n",
    "        edge_mlp_dropout=0.1,\n",
    "        keep_prob=0.8,\n",
    "        conf_dim=1,\n",
    "        stance_dim=3\n",
    "    )\n",
    ")\n",
    "\n",
    "TRAIN_ARGS = dict(\n",
    "    epochs = 30,\n",
    "    lr = 0.001,\n",
    "    patience = 6,\n",
    "    min_delta = 3e-4,\n",
    "    neg_sample_ratio = 0.5,\n",
    "    temp_reg_weight = 0.1,\n",
    "    val_n_last = 1, # or val_pct_last = 0.25 (pick either one)\n",
    "    val_gap_n = 2,\n",
    "    task_weights = {\"link\": 1.0, \"conf\": 1.0, \"stance\": 1.0}\n",
    ")\n",
    "\n",
    "# See created model\n",
    "_ = create_and_describe_model(MODEL_ARGS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b47bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n",
      "\n",
      "Dataset Overview:\n",
      "  - Total graphs: 77\n",
      "  - Device: cuda\n",
      "  - Training mode: full\n",
      "  - Task weights: {'link': 1.0, 'conf': 1.0, 'stance': 1.0}\n",
      "  - Tasks: Link, Confidence, Stance\n",
      "   + Subreddit 0: 23 graphs | 4,286 nodes | 14,580 edges | Avg: 633.9 edges/graph\n",
      "   + Stance Dist: [0.414, 0.290, 0.296] (disagree/neutral/agree)\n",
      "   + Subreddit 1: 10 graphs | 1,910 nodes | 1,425 edges | Avg: 142.5 edges/graph\n",
      "   + Stance Dist: [0.326, 0.225, 0.449] (disagree/neutral/agree)\n",
      "   + Subreddit 2: 26 graphs | 4,328 nodes | 4,308 edges | Avg: 165.7 edges/graph\n",
      "   + Stance Dist: [0.406, 0.283, 0.311] (disagree/neutral/agree)\n",
      "   + Subreddit 3: 9 graphs | 6,705 nodes | 7,677 edges | Avg: 853.0 edges/graph\n",
      "   + Stance Dist: [0.359, 0.214, 0.427] (disagree/neutral/agree)\n",
      "   + Subreddit 4: 9 graphs | 7,022 nodes | 7,296 edges | Avg: 810.7 edges/graph\n",
      "   + Stance Dist: [0.402, 0.245, 0.353] (disagree/neutral/agree)\n",
      "\n",
      "Global Statistics:\n",
      "  - Total nodes: 24,251\n",
      "  - Total edges: 35,286\n",
      "  - Avg nodes/graph: 314.9\n",
      "  - Avg edges/graph: 458.3\n",
      "\n",
      "Global Edge Attribute Analysis:\n",
      "\n",
      "Edge Attribute (Full Dataset):\n",
      "  - Confidence: μ=0.521, σ=0.375\n",
      "  - Stance dist: [0.395, 0.261, 0.344] (disagree/neutral/agree)\n",
      "  - Confidence correlations: disagree:+0.084, neutral:-0.184, agree:+0.084\n",
      "\n",
      "==================================================\n",
      "Training for Test Subreddit: 0\n",
      "==================================================\n",
      "\n",
      "Data Split:\n",
      "  - Training: 3 subreddits + early timesteps from val 1 → 52 graphs\n",
      "    Train subreddits: [2, 3, 4, '1 (partial)']\n",
      "  - Validation: Subreddit 1 latest timesteps: [9] → 1 graph(s)\n",
      "  - Temporal Gap (g=1): Subreddit 1 timesteps skipped: []\n",
      "  - Testing:  Subreddit 0 → 23 graphs\n",
      "\n",
      "Edge Attribute (Training):\n",
      "  - Confidence: μ=0.537, σ=0.381\n",
      "  - Stance dist: [0.382, 0.240, 0.378] (disagree/neutral/agree)\n",
      "  - Confidence correlations: disagree:+0.077, neutral:-0.201, agree:+0.100\n",
      "\n",
      "Edge Attribute (Validation (Sub 1)):\n",
      "  - Confidence: μ=0.602, σ=0.389\n",
      "  - Stance dist: [0.223, 0.235, 0.542] (disagree/neutral/agree)\n",
      "  - Confidence correlations: disagree:-0.003, neutral:-0.088, agree:+0.077\n",
      "\n",
      "Loss Balancing:\n",
      "  - Link pos_weight: 50.000 (pos/neg ratio: 0.0015)\n",
      "  - Stance weights:  [2.615, 4.167, 2.649]\n",
      "\n",
      "Model Configs:\n",
      "  - Total parameters: 4,741,704 (trainable: 4,741,704)\n",
      "  - Base LR: 1.00e-04\n",
      "  - Log-var LR: 1.00e-05\n",
      "  - Custom task weights: {'link': 1.0, 'conf': 1.0, 'stance': 1.0}\n",
      "\n",
      "*** BEGIN TRAINING ***\n",
      "  - Max epochs: 30\n",
      "  - Early stopping patience: 6 epochs\n",
      "  - Negative sampling ratio: 0.50\n",
      "  - Temporal regularization weight: 0.100\n",
      "\n",
      "Epoch   0:\n",
      "  - Train: Total=9.6607 | Link=18.5524 | Conf=0.0437 | Stance=0.7293\n",
      "  - Val:   Total=5.0607 | Link=9.5319 | Conf=0.0533 | Stance=0.5405\n",
      "  - Uncertainty: Link=1.000 | Conf=1.000 | Stance=1.000\n",
      "  - LR: 1.00e-04\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m model, results, cv_history = run_cv_training(\n\u001b[32m      4\u001b[39m     graph_data = PYG_GRAPHS,\n\u001b[32m      5\u001b[39m     model_args = MODEL_ARGS,\n\u001b[32m      6\u001b[39m     train_args = TRAIN_ARGS,\n\u001b[32m      7\u001b[39m     model_class = MultitaskDebateGNN,\n\u001b[32m      8\u001b[39m     live_plot = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# Plot cv losses\u001b[39;00m\n\u001b[32m     12\u001b[39m plot_cv_losses(cv_history)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mrun_cv_training\u001b[39m\u001b[34m(graph_data, model_args, train_args, model_class, live_plot)\u001b[39m\n\u001b[32m     57\u001b[39m     torch.cuda.empty_cache()\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m     model, results, cv_history = train_gnn_live(\n\u001b[32m     61\u001b[39m         all_graphs=\u001b[38;5;28mgetattr\u001b[39m(graph_data, \u001b[33m\"\u001b[39m\u001b[33mpyg_graphs\u001b[39m\u001b[33m\"\u001b[39m, graph_data),\n\u001b[32m     62\u001b[39m         model_args=model_args,\n\u001b[32m     63\u001b[39m         train_args=train_args,\n\u001b[32m     64\u001b[39m         model_class=model_class,\n\u001b[32m     65\u001b[39m         live_plot=live_plot,\n\u001b[32m     66\u001b[39m     )\n\u001b[32m     67\u001b[39m     plot_cv_losses(cv_history=cv_history)\n\u001b[32m     68\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m model, results, cv_history\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\OneDrive\\ecs_msc_project\\src\\models\\multitask_debate_gnn.py:848\u001b[39m, in \u001b[36mtrain_gnn_live\u001b[39m\u001b[34m(all_graphs, model_args, train_args, model_class, live_plot)\u001b[39m\n\u001b[32m    843\u001b[39m neg = negative_sampling(\n\u001b[32m    844\u001b[39m     g.edge_index, g.x.size(\u001b[32m0\u001b[39m), \u001b[38;5;28mint\u001b[39m(g.edge_index.size(\u001b[32m1\u001b[39m) * neg_sample_ratio)\n\u001b[32m    845\u001b[39m ).to(device)\n\u001b[32m    847\u001b[39m \u001b[38;5;66;03m# Compute losses\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m848\u001b[39m loss_total, loss_link, loss_conf, loss_stance = model.compute_losses(\n\u001b[32m    849\u001b[39m     z=z, \n\u001b[32m    850\u001b[39m     edge_attr=g.edge_attr, \n\u001b[32m    851\u001b[39m     pos_edge_index=g.edge_index, \n\u001b[32m    852\u001b[39m     neg_edge_index=neg,\n\u001b[32m    853\u001b[39m     pos_weight=pos_weight,\n\u001b[32m    854\u001b[39m     stance_weight=stance_weight,\n\u001b[32m    855\u001b[39m     task_weights=task_weights\n\u001b[32m    856\u001b[39m )\n\u001b[32m    858\u001b[39m \u001b[38;5;66;03m# Temporal regularization\u001b[39;00m\n\u001b[32m    859\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m temp_reg_weight > \u001b[32m0.0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\OneDrive\\ecs_msc_project\\src\\models\\multitask_debate_gnn.py:525\u001b[39m, in \u001b[36mMultitaskDebateGNN.compute_losses\u001b[39m\u001b[34m(self, z, edge_attr, pos_edge_index, neg_edge_index, pos_weight, stance_weight, task_weights)\u001b[39m\n\u001b[32m    523\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.edge_head \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    524\u001b[39m     edge_idx_all = torch.cat([pos_edge_index, neg_edge_index], dim=\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m525\u001b[39m     edge_attr_pred = \u001b[38;5;28mself\u001b[39m.predict_edge_attr(z, edge_idx_all)\n\u001b[32m    527\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m edge_attr_pred \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    528\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m edge_attr_pred.dim() == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\OneDrive\\ecs_msc_project\\src\\models\\multitask_debate_gnn.py:396\u001b[39m, in \u001b[36mMultitaskDebateGNN.predict_edge_attr\u001b[39m\u001b[34m(self, z, edge_index)\u001b[39m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch.isnan(edge_input).any():\n\u001b[32m    394\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNaN detected in edge prediction input\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m396\u001b[39m raw = \u001b[38;5;28mself\u001b[39m.edge_head(edge_input)\n\u001b[32m    398\u001b[39m \u001b[38;5;66;03m# Process outputs with stability safeguards\u001b[39;00m\n\u001b[32m    399\u001b[39m results = []\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\anaconda3\\envs\\mscenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\anaconda3\\envs\\mscenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\anaconda3\\envs\\mscenv\\Lib\\site-packages\\torch\\nn\\modules\\container.py:244\u001b[39m, in \u001b[36mSequential.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    242\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[32m    243\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m244\u001b[39m         \u001b[38;5;28minput\u001b[39m = module(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m    245\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\anaconda3\\envs\\mscenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._call_impl(*args, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\anaconda3\\envs\\mscenv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(*args, **kwargs)\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\anaconda3\\envs\\mscenv\\Lib\\site-packages\\torch\\nn\\modules\\normalization.py:217\u001b[39m, in \u001b[36mLayerNorm.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m F.layer_norm(\n\u001b[32m    218\u001b[39m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m.normalized_shape, \u001b[38;5;28mself\u001b[39m.weight, \u001b[38;5;28mself\u001b[39m.bias, \u001b[38;5;28mself\u001b[39m.eps\n\u001b[32m    219\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\vduch\\anaconda3\\envs\\mscenv\\Lib\\site-packages\\torch\\nn\\functional.py:2905\u001b[39m, in \u001b[36mlayer_norm\u001b[39m\u001b[34m(input, normalized_shape, weight, bias, eps)\u001b[39m\n\u001b[32m   2895\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_variadic(\u001b[38;5;28minput\u001b[39m, weight, bias):\n\u001b[32m   2896\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m   2897\u001b[39m         layer_norm,\n\u001b[32m   2898\u001b[39m         (\u001b[38;5;28minput\u001b[39m, weight, bias),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2903\u001b[39m         eps=eps,\n\u001b[32m   2904\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m2905\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m torch.layer_norm(\n\u001b[32m   2906\u001b[39m     \u001b[38;5;28minput\u001b[39m, normalized_shape, weight, bias, eps, torch.backends.cudnn.enabled\n\u001b[32m   2907\u001b[39m )\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"Training model...\")\n",
    "\n",
    "model, results, cv_history = run_cv_training(\n",
    "    graph_data = PYG_GRAPHS,\n",
    "    model_args = MODEL_ARGS,\n",
    "    train_args = TRAIN_ARGS,\n",
    "    model_class = MultitaskDebateGNN,\n",
    "    live_plot = False\n",
    ")\n",
    "\n",
    "# Plot cv losses\n",
    "plot_cv_losses(cv_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe2b9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mscenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
